{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save the checkpoint \n",
    "model.class_to_idx = dataloaders['train'].dataset.class_to_idx\n",
    "model.epochs = num_epochs\n",
    "checkpoint = {'input_size': [3, 224, 224],\n",
    "                 'batch_size': dataloaders['train'].batch_size,\n",
    "                  'output_size': 102,\n",
    "                  'state_dict': model.state_dict(),\n",
    "                  'optimizer_dict':optimizer.state_dict(),\n",
    "                  'class_to_idx': model.class_to_idx,\n",
    "                  'epoch': model.epochs}\n",
    "torch.save(checkpoint, 'vgg16_flower.pth')\n",
    "\n",
    "# TODO: Write a function that loads a checkpoint and rebuilds the model\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = models.vgg16(pretrained=False)\n",
    "    \n",
    "    classifier = nn.Sequential(OrderedDict([\n",
    "                              ('fc1', nn.Linear(num_features, 512)),\n",
    "                              ('relu', nn.ReLU()),\n",
    "                              ('drpot', nn.Dropout(p=0.5)),\n",
    "                              ('hidden', nn.Linear(512, 100)),                       \n",
    "                              ('fc2', nn.Linear(100, 102)),\n",
    "                              ('output', nn.LogSoftmax(dim=1)),\n",
    "                              ]))\n",
    "    \n",
    "    model.classifier = classifier\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model, checkpoint['class_to_idx']\n",
    "  \n",
    "# get index to class mapping\n",
    "loaded_model, class_to_idx = load_checkpoint('vgg16_flower.pth')\n",
    "idx_to_class = { v : k for k,v in class_to_idx.items()}\n",
    "\n",
    "# Testing checkpoint\n",
    "\n",
    "loaded_model.eval()\n",
    "images, labels = next(iter(dataloaders['test']))\n",
    "output = loaded_model.forward(Variable(images[:2]))\n",
    "ps = torch.exp(output).data\n",
    "print(ps.max(1)[1])\n",
    "\n",
    "\n",
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    \n",
    "    # TODO: Process a PIL image for use in a PyTorch model\n",
    "\n",
    "    size = 256, 256\n",
    "    image.thumbnail(size, Image.ANTIALIAS)\n",
    "    image = image.crop((128 - 112, 128 - 112, 128 + 112, 128 + 112))\n",
    "    npImage = np.array(image)\n",
    "    npImage = npImage/255.\n",
    "        \n",
    "    imgA = npImage[:,:,0]\n",
    "    imgB = npImage[:,:,1]\n",
    "    imgC = npImage[:,:,2]\n",
    "    \n",
    "    imgA = (imgA - 0.485)/(0.229) \n",
    "    imgB = (imgB - 0.456)/(0.224)\n",
    "    imgC = (imgC - 0.406)/(0.225)\n",
    "        \n",
    "    npImage[:,:,0] = imgA\n",
    "    npImage[:,:,1] = imgB\n",
    "    npImage[:,:,2] = imgC\n",
    "    \n",
    "    npImage = np.transpose(npImage, (2,0,1))\n",
    "    \n",
    "    return npImage\n",
    "    \n",
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax\n",
    "    \n",
    "def predict(image_path, model, topk=5):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    \n",
    "    # TODO: Implement the code to predict the class from an image file\n",
    "    \n",
    "    image = torch.FloatTensor([process_image(Image.open(image_path))])\n",
    "    model.eval()\n",
    "    output = model.forward(Variable(image))\n",
    "    pobabilities = torch.exp(output).data.numpy()[0]\n",
    "    \n",
    "\n",
    "    top_idx = np.argsort(pobabilities)[-topk:][::-1] \n",
    "    top_class = [idx_to_class[x] for x in top_idx]\n",
    "    top_probability = pobabilities[top_idx]\n",
    "\n",
    "    return top_probability, top_class\n",
    "print (predict('flower_data/test/2/image_05100.jpg', loaded_model))    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
